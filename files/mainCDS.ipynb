{
 "metadata": {
  "name": "",
  "signature": "sha256:56f99980f5298bb76b757fa64ea38cfe474ca3021398eb27fcc73d616c3631b5"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "National bank of GreecejQuery20305518563586789852_1401671015467 in Ontology\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#from imports import *\n",
      "%pylab inline \n",
      "from suds.client import Client\n",
      "url = 'http://annotate.ijs.si/NewsMonitor/NewsMonitor.svc?wsdl'\n",
      "########client = Client(url)\n",
      "#print client\n",
      "print \"Loading packages\"\n",
      "import scipy as sp\n",
      "import re\n",
      "import os\n",
      "import json # for dumping data in files and reading them.\n",
      "import urllib2\n",
      "\n",
      "import pandas as pd\n",
      "from scipy import stats, optimize, interpolate\n",
      "import csv,codecs,cStringIO\n",
      "\n",
      "\n",
      "#os.chdir('/Users/asher/Google Drive/CDS/pyfiles')\n",
      "#(\"F:/Nima/Google Drive/March 22-13/Google Drive/Network/Irena/CDS/CDS/pyfiles\")\n",
      "print \"Done loading.\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Populating the interactive namespace from numpy and matplotlib\n",
        "Loading packages"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Done loading."
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "/usr/local/lib/python2.7/dist-packages/pandas/io/excel.py:626: UserWarning: Installed openpyxl is not supported at this time. Use >=1.6.1 and <2.0.0.\n",
        "  .format(openpyxl_compat.start_ver, openpyxl_compat.stop_ver))\n"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "os.chdir('/home/nimadt/Downloads/CDS/CDS/pyfiles')#('/media/removable/KINGSTON/CDS/pyfiles')\n",
      "fromDate='2011-10-01'\n",
      "toDate='2013-12-30'\n",
      "#CDSPath = '/Users/asher/Google Drive/CDS/'\n",
      "CDSPath = '/home/nimadt/Downloads/CDS/CDS/'#'/media/removable/KINGSTON/CDS/'\n",
      "CDSPathY=CDSPath+'YahooEnts/'\n",
      "OntPath= CDSPath+'Ontology/'\n",
      "OcPath = CDSPath+'files/Occurrence/'\n",
      "RawOcPath=OcPath+'Raw/'\n",
      "SentPath = CDSPath +'files/Sentiment/'\n",
      "OcSlick= CDSPath+'files/Slick/Occurrence/'\n",
      "SentSlick = CDSPath +'files/Slick/Sentiment/'\n",
      "onsa= CDSPath+'files/Slick/MaxAll/Occurrence/'\n",
      "sensa= CDSPath+'files/Slick/MaxAll/Sentiment/'\n",
      "RawSentPath=SentPath+'Raw/'\n",
      "if not os.path.exists(OntPath): os.makedirs(OntPath)\n",
      "if not os.path.exists(OcPath): os.makedirs(OcPath)\n",
      "if not os.path.exists(RawOcPath): os.makedirs(RawOcPath)\n",
      "if not os.path.exists(SentPath): os.makedirs(SentPath)\n",
      "if not os.path.exists(RawOcPath): os.makedirs(RawOcPath)\n",
      "if not os.path.exists(OcSlick): os.makedirs(OcSlick)\n",
      "if not os.path.exists(SentSlick): os.makedirs(SentSlick)\n",
      "if not os.path.exists(RawSentPath): os.makedirs(RawSentPath)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#from Ont import *\n",
      "%run -i Ont.py\n",
      "\n",
      "#Ontology functions like:\n",
      "# On=Ontology()\n",
      "# nums # number of entities in Classes\n",
      "On[1][1681]=u'Namecoin'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#from NewsData import *\n",
      "%run -i NewsData\n",
      "# - Link # urls of entities containing 'word'\n",
      "# - OcVol\n",
      "# - Sentiment\n",
      "# - RawOcVol\n",
      "# - RawOcVols\n",
      "# - RawSentiment\n",
      "# - Insert0\n",
      "# - GetData"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#from CustomFuncs import *\n",
      "%run -i CustomFuncs"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Yahoo data\n",
      "# %run -i YahooFuncs\n",
      "# - Yurl  #the url for ticker data\n",
      "# - GetStocks #\n",
      "# yticks # pandas: file containing yahoo tickers and names\n",
      "# yasc # ascii names and ticker symbols\n",
      "# Onasc #\"\" of ontology entities\n",
      "# Kleanup1 # get rid of Co. Inc. etc. simplify name matching"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#import urllib2\n",
      "\n",
      "def Yurl(tck , Int='d', datei='2005-04-20', datef='2014-04-20'):\n",
      "    \"\"\"tck= one ticker symbol; Int=period: d=daily, w=weekly, m=monthly.\"\"\"\n",
      "    return 'http://ichart.yahoo.com/table.csv?s='+tck+ \\\n",
      "                        '&a='+str(int(datei[5:7])-1)+'&b='+datei[-2:]+'&c='+datei[:4]+\\\n",
      "                        '&d='+str(int(datef[5:7])-1)+'&e='+datef[-2:]+'&f='+datef[:4]+\\\n",
      "                        '&g='+Int+'&ignore=.csv'\n",
      "\n",
      "\n",
      "def GetStock(tck, Int='d', datei=fromDate, datef=toDate, out=1, save_path=CDSPathY+'stocks/'):\n",
      "    \"\"\"tck= ticker or list of ticker symbol; Int=period: d=daily, w=weekly, m=monthly.\"\"\"\n",
      "    if type(tck)==str: #If there was just one entry, we have a string. \n",
      "        tck=[tck] #Make it a list, for compatibility with the rest\n",
      "    for i in tck: #for more than one stock, we have a listof tickers.\n",
      "            stocks=[]\n",
      "            try:\n",
      "                \n",
      "                u=urllib2.urlopen(Yurl(tck =i,Int=Int, datei=datei,datef=datef))\n",
      "                fname=save_path+i+\"(\"+Int+\"),(\"+datei+\")-(\"+datef+\").csv\"\n",
      "                #if os.path.isfile(fname): mode='rw'\n",
      "                #else: mode='a+'\n",
      "                mode='w+'\n",
      "                f= open(fname,mode)\n",
      "                f.write(u.read())\n",
      "                f.seek(0)\n",
      "                a=f.readline()\n",
      "                a=a.replace(' ','_')\n",
      "                f.seek(0)\n",
      "                f.writelines(a)\n",
      "                f.write('')\n",
      "                f.close()\n",
      "                if out: stocks+=[pd.read_csv(fname)]\n",
      "            except urllib2.HTTPError: print \"Ticker %s not found!! Skipping...\" % i\n",
      "    return stocks\n",
      "\n",
      "Yticks=pd.read_excel(CDSPathY+'yticks.xlsx','Stock',header=3, keep_default_na=0)\n",
      "yy=array([Yticks.Name,Yticks.Ticker]).T # just name and ticker symbol\n",
      "yyfix=[val for val in yy if val[0]!=''] # remove empties\n",
      "yasc=[[x[0].encode('ascii', 'ignore'),x[1]] for x in yyfix]\n",
      "yasc=[x for x in yasc if x[0]!='N/A'] #removed unicode chars\n",
      "Onasc=[x.encode('ascii', 'ignore') for x in On[1]] #removed unicode chars\n",
      "\n",
      "def Kleanup(s): # compress generic words in names\n",
      "    return s.replace('.','').replace(',','').replace(';','').replace(':','')\\\n",
      "           .replace('\"','').replace('(','').replace(')','').replace('$','')\\\n",
      "           .lower().replace('company','co').replace('companies','co')\\\n",
      "           .replace('incorporated','inc').replace('holding','hld').replace('holdings','hld')\\\n",
      "    .replace('hldg','hld').replace('hldgs','hld').replace('hlds','hld').replace('yield','yld')\\\n",
      "    .replace('national','natl').replace('corporation','corp').replace('limited','ltd')\n",
      "    \n",
      "def Kleanup1(s): # get rid of all generic names and extra chars messing up the name matching\n",
      "    s=(s+' ').lower().replace('n/a ', '****')\\\n",
      "           .replace('.','').replace(',',' ').replace(';',' ').replace(':',' ').replace('+',' ')\\\n",
      "           .replace('\"',' ').replace('(',' ').replace(')',' ')\\\n",
      "           .replace('$',' ').replace('&','').replace('/', '')\\\n",
      "           .replace(' company ',' ').replace(' companies ',' ').replace(' co ',' ')\\\n",
      "           .replace(' incorporated ',' ').replace(' inc ',' ').replace(' and ',' ')\\\n",
      "           .replace(' holding ',' ').replace(' holdings ',' ').replace(' hld ',' ')\\\n",
      "           .replace(' hldg ',' ').replace(' hldgs ',' ').replace(' hlds ',' ')\\\n",
      "           .replace(' group ',' ').replace('grp', ' ')\\\n",
      "           .replace(' corporation ',' ').replace(' corp ',' ').replace(' se ', ' ')\\\n",
      "           .replace(' limited ', ' ').replace(' ltd ', ' ').replace(' llc ', ' ')\\\n",
      "           .replace(' sa ', ' ').replace(' spa ', ' ').replace(' plc ', ' ').replace(' ag ', ' ')\\\n",
      "           .replace(' nv ', ' ').replace(' as ', ' ').replace(' sgr', ' ').replace(' sgiic', ' ')\\\n",
      "           .replace(' ae ', ' ').replace(' ab ', ' ').replace(' gruppe ', ' ')\\\n",
      "           .replace(' national ',' natl ').replace(' yield ',' yld ')\n",
      "    s=' '.join(s.split())\n",
      "    #s=' '.join([x for x in s.split() if (x!='sa' and x!='spa')])\n",
      "    return s\n",
      "# we clean up the names, \n",
      "\n",
      "YKlean=array([[Kleanup1(x[0]),x[1]] for x in yasc]) # y1--> YKlean\n",
      "\n",
      "#Bankarr=array([Kleanup1(s) for s in Onasc[nums[:3].sum():nums[:4].sum()]]) #Bank names from Ontology\n",
      "# banks of Ontology which were found in YTicks\n",
      "\n",
      "#Bnkfound=[[[oni, x] for x in YKlean if oni.replace(' ','') in x[0].replace(' ','') ] for oni in Bankarr] #y1 -> YKlean\n",
      "# how many missing (not matched)\n",
      "#len([Bankarr[i] for i in range(len(Bnkfound)) if Bnkfound[i]==[]])\n",
      "\n",
      "# match entities in a particular class, or list of classes in ontology with yticks.\n",
      "def MatchY(ls=[3]): \n",
      "    \"\"\" look up classes in Ontology and match the entities to Y! ticks\"\"\"\n",
      "    Mc=[]\n",
      "    for l in ls:\n",
      "        entz=[Kleanup1(s) for s in Onasc[nums[:l].sum():nums[:l+1].sum()]]# for i in ls]\n",
      "        Matched=[[[oni, x] for x in YKlean \\\n",
      "                  if (' '+oni+' ' in ' '+x[0]+' ') or (' '+x[0]+' ' in ' '+oni+' ') ] for oni in entz]\n",
      "                  # the extra space ' ': to avoid usage of word as fragment\n",
      "                  #if (oni.replace(' ','') in x[0].replace(' ','')) or (oni.replace(' ','') in x[0].replace(' ','')) ] for oni in entz]\n",
      "        Mc+= Matched\n",
      "        print \"\\nMissing %d from %s\" % (len([entz[i] for i in range(len(Matched)) if Matched[i]==[]]),On[0][l])\n",
      "        print [entz[i] for i in range(len(Matched)) if Matched[i]==[]]\n",
      "    return array(Mc)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x=rand(10)\n",
      "x[np.argsort(x)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "array([ 0.09414816,  0.17701542,  0.22892832,  0.51113191,  0.59800222,\n",
        "        0.62826784,  0.88987818,  0.90886068,  0.9683025 ,  0.99781267])"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "AllSents=[];\n",
      "AllStats=[];\n",
      "AllOx=[];\n",
      "AllOxStats=[];\n",
      "for i in range(len(On[1])): # get the individual sentiments of all banks\n",
      "  try:\n",
      "    dat=pd.read_csv(SentSlick+\"S-\"+str(i)+'('+fromDate+','+toDate+').csv')\n",
      "    AllSents+=[dat.values.T[0]]\n",
      "    AllStats+=[[i,On[1][i],mean(dat.values.T[0]), std(dat.values.T[0]), stats.skew(dat.values.T[0])]]\n",
      "    #print (i,On[1][i],\"mean=\"+str(mean(dat.values.T[0])), \"std=\"+str(std(dat.values.T[0])), \"skew=\"+str(stats.skew(dat.values.T[0])))\n",
      "    dat=pd.read_csv(OcSlick+\"Oc-\"+str(i)+'('+fromDate+','+toDate+').csv')\n",
      "    AllOx+=[dat.values.T[0]]\n",
      "    AllOxStats+=[[i,On[1][i],mean(dat.values.T[0]), std(dat.values.T[0]), stats.skew(dat.values.T[0])]]\n",
      "    #print (i,On[1][i],\"mean=\"+str(mean(dat.values.T[0])), \"std=\"+str(std(dat.values.T[0])), \"skew=\"+str(stats.skew(dat.values.T[0])))\n",
      "  except IOError:\n",
      "    print (\"All\",i, \"!!!\"+On[1][i]+\" not found!!!\")\n",
      "\n",
      "AllSents=array(AllSents)\n",
      "AllOx=array(AllOx)\n",
      "AllSn=[i[0] for i in AllStats]\n",
      "AllOn=[i[0] for i in AllOxStats]\n",
      "clss=On[0][:18]+On[0][20:] # remove Over the counter and Stock from nums (cuz they're absent.)\n",
      "\n",
      "nums1=[re.findall('[0-9].*(?=\\))', s) for s in clss]\n",
      "nm=[int(nn[0]) for nn in nums1 if nn!=[]]\n",
      "\n",
      "def OntClassFinder(a='Bank'): # <-- OcSent\n",
      "    \"\"\"Finds all classes, their # of entities, and start/end positions in entity list\n",
      "    \"\"\"\n",
      "    if (type(a) is str) or (type(a) is unicode):\n",
      "        #ls=[ s for s in On[0] if a.lower() in s.lower()]\n",
      "        ls=[[i,nums1[i], clss[i]] for i in range(len(clss)) if a.lower() in clss[i].lower()]\n",
      "        ns=[[int16([s for s in nums1[:xs[0]] if len(s)==1]).sum()\n",
      "            ,int16([s for s in nums1[:xs[0]+1] if len(s)==1]).sum()] for xs in ls]\n",
      "    return ls ,ns\n",
      "def ClassNums(a='Bank'): #\n",
      "    \"\"\" Get numbers present. Look into downloaded Occ/Sent files and find which entities of a class containing word 'a' is present.  \n",
      "    \"\"\"\n",
      "    x=OntClassFinder(a)[1] #indices from OntClassFinder\n",
      "    li=[]\n",
      "    for xx in x:\n",
      "        li+=[[ns for ns in AllSn if xx[1]> ns>=xx[0]]]\n",
      "    return li\n",
      "def ClassNews(a='Bank'):\n",
      "    \"\"\" Get Sents and Ox present. Look into downloaded Occ/Sent files and fid which entities of a class containing word 'a' is present.  \n",
      "    \"\"\"\n",
      "    x=OntClassFinder(a)[1]\n",
      "    li=[]\n",
      "    for xx in x:\n",
      "        li+=[[[AllSents[i], AllOx[i]] for i in range(len(AllSn)) if xx[1]> AllSn[i]>=xx[0]]]\n",
      "    return li\n",
      "\n",
      "AllStats=array(AllStats)\n",
      "AllOxStats=array(AllOxStats)\n",
      "\n",
      "def ClassStats(a='Bank'):\n",
      "    \"\"\" Get Sents and Ox present. Look into downloaded Occ/Sent files and fid which entities of a class containing word 'a' is present.  \n",
      "    \"\"\"\n",
      "    x=OntClassFinder(a)[1]\n",
      "    li=[]\n",
      "    for xx in x:\n",
      "        li+=[array([float64([AllStats[i,2:],AllOxStats[i,2:]]) for i in range(len(AllSn)) if xx[1]> AllSn[i]>=xx[0]])]\n",
      "    return li\n",
      "\n",
      "NewSents=[];\n",
      "NewStats=[];\n",
      "NewOx=[];\n",
      "NewOxStats=[];\n",
      "for i in range(array(nm).sum()): # get the individual sentiments of all banks\n",
      "  try:\n",
      "    dat=pd.read_csv(SentSlick+\"S-\"+str(i)+'('+fromDate+','+toDate+'),min_oc=%d,max_oc=%s.csv' \\\n",
      "                       %(2,str(10000)))\n",
      "    NewSents+=[dat.values.T[0]]\n",
      "    NewStats+=[[i,On[1][i],mean(dat.values.T[0]), std(dat.values.T[0]), stats.skew(dat.values.T[0])]]\n",
      "    #print (i,On[1][i],\"mean=\"+str(mean(dat.values.T[0])), \"std=\"+str(std(dat.values.T[0])), \"skew=\"+str(stats.skew(dat.values.T[0])))\n",
      "    dat=pd.read_csv(OcSlick+\"Oc-\"+str(i)+'('+fromDate+','+toDate+'),min_oc=%d,max_oc=%s.csv' \\\n",
      "                       %(2,str(10000)))\n",
      "    NewOx+=[dat.values.T[0]]\n",
      "    NewOxStats+=[[i,On[1][i],mean(dat.values.T[0]), std(dat.values.T[0]), stats.skew(dat.values.T[0])]]\n",
      "    #print (i,On[1][i],\"mean=\"+str(mean(dat.values.T[0])), \"std=\"+str(std(dat.values.T[0])), \"skew=\"+str(stats.skew(dat.values.T[0])))\n",
      "  except IOError:\n",
      "    print (\"New raw\",i, \"!!!\"+On[1][i]+\" not found!!!\")\n",
      "NewSents=array(NewSents)\n",
      "NewOx=array(NewOx)\n",
      "NewStats=array(NewStats)\n",
      "NewOxStats=array(NewOxStats)\n",
      "NewSn=NewStats[:,0]#[i[0] for i in bnStats]\n",
      "NewOn=NewOxStats[:,0]#[i[0] for i in bnOxStats]\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def FillPrices(Yfile, datei=fromDate, datef=toDate):\n",
      "    \"\"\"Takes Y!Finance csv read in pandas. Outs Adj Close with missing dates filled with previous days.\n",
      "    \"\"\"\n",
      "    #1. convert dates to nums with datei -> 0\n",
      "    dats=int0([datestr2num(s)-datestr2num(datei) for s in Yfile.values[::-1,0]if s!=datef])\n",
      "    temp=array([0.]*int(datestr2num(datef)-datestr2num(datei)))\n",
      "    temp[dats]=Yfile.values[::-1,-1]\n",
      "    for i in range(1,int(datestr2num(datef)-datestr2num(datei))-1):\n",
      "        if (temp[i]==0.) & (temp[i-1]!=0.): temp[i]=temp[i-1]\n",
      "    return temp\n",
      "\n",
      "def FillY(Yfile, datei=fromDate, datef=toDate):\n",
      "    \"\"\"Takes Y!Finance csv read in pandas. Outs Adj Close with missing dates filled with previous days.\n",
      "    \"\"\"\n",
      "    #1. convert dates to nums with datei -> 0\n",
      "    dats=int0([datestr2num(s)-datestr2num(datei) for s in Yfile.values[::-1,0]])#if s!=datef])\n",
      "    temp=array([[0.]*(Yfile.columns.size-1)]*int(datestr2num(datef)-datestr2num(datei)+1))\n",
      "    print temp.shape\n",
      "    print Yfile.values[::-1,1:].shape\n",
      "    print dats.shape\n",
      "    temp[dats]=float64(Yfile.values[::-1,1:])\n",
      "    for i in range(1,int(datestr2num(datef)-datestr2num(datei))):\n",
      "        if (float64(temp[i])==zeros(Yfile.columns.size-1)).any() &\\\n",
      "        (float64(temp[i-1])!=zeros(Yfile.columns.size-1)).any(): temp[i]=temp[i-1]\n",
      "    return temp\n",
      "\n",
      "def ShrinkSents(Yfile,Sent, datei=fromDate, datef=toDate):\n",
      "    \"\"\"Takes Y!Finance csv read in pandas. Outs Adj Close with missing dates filled with previous days.\n",
      "    \"\"\"\n",
      "    #1. convert dates to nums with datei -> 0\n",
      "    dats=int0([datestr2num(s)-datestr2num(datei) for s in Yfile.values[::-1,0]])\n",
      "    #temp=array([0.]*int(datestr2num(datef)-datestr2num(datei)+1))\n",
      "    #temp[dats]=Yfile.values[::-1,-1]\n",
      "    #if we:\n",
      "    Sents=zeros_like(dats)\n",
      "    for i in range(1,len(dats)):\n",
      "        Sents[i]=Sent[dats[i-1]:dats[i]].sum()#*exp\n",
      "    return Sents\n",
      "\n",
      "def CosCorr(a,b):\n",
      "    return a.dot(b.T)/sqrt(a.dot(a.T)*b.dot(b.T))\n",
      "\n",
      "def dPrices(prices, w=1, interval=400, days=10,*kw ):\n",
      "    \"\"\" Calc. deriv. of prices, w= deriv window, interval= length of T series for lagged corr.\n",
      "    days= max lag\"\"\"\n",
      "    iv = interval\n",
      "    dpr = prices[:,w:]-prices[:,:-w]\n",
      "    \n",
      "    ls=[]\n",
      "    shufls=[]\n",
      "    dpr_shuff=dpr[:,argsort(rand(dpr.shape[1]))]\n",
      "    for j in range(iv, dpr.shape[1]-days):\n",
      "        spls=[]\n",
      "        spsh=[]\n",
      "        for i in range(days):\n",
      "            spls+=[CosCorr(dpr[:,j-iv:j],dpr[:,i+j-iv:j+i])]\n",
      "            spsh+=[CosCorr(dpr_shuff[:,j-iv:j],dpr_shuff[:,i+j-iv:j+i])]\n",
      "        ls+=[spls]\n",
      "        shufls+=[spsh]\n",
      "    return array(ls), array(shufls) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "End of Preamble"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def GetData1(num1, num2=[''],datei=fromDate, datef=toDate, min_oc=2, max_oc='all', slick=1, savefile=1,out=0, log=0, ): \n",
      "    \"\"\"num1,2 are the positions in the Ontology list. Date in format 'yyyy-mm-dd'\n",
      "    slick(=0,1): if set, data is converted to one list of numbers \n",
      "                without the dates (one number for each day from\n",
      "                datei to datef, with zeros inserted,)\n",
      "                files will be saved in Slick subfolder,\n",
      "    savefile(=0,1): if csv should be saved,\n",
      "    out(=0,1):  output list of data arrays,\n",
      "    log(=0,1):  print data while running,\n",
      "    \"\"\"\n",
      "    e1=[array(On[1])[num1],array(On[2])[num1]] # get name (for reference) and url \n",
      "    if num2!=['']:\n",
      "        e2=[array(On[1])[num2],array(On[2])[num2]]\n",
      "    else:\n",
      "        e2=[[''],['']] #[name, url]\n",
      "    res=[]\n",
      "    print \" from \", datei, \" to \", datef, \": Occurrence of \",\n",
      "    #b=[[[]]*len(num2)]* len(num1)\n",
      "    a=[]; a2=[];\n",
      "    for i in range(len(num1)):\n",
      "      print \"(\", e1[0][i],\") with:\"\n",
      "      for j in range(len(num2)):\n",
      "        try:\n",
      "            b0=zeros(int(datestr2num(datef)-datestr2num(datei)+1))\n",
      "            b02=zeros(int(datestr2num(datef)-datestr2num(datei)+1))\n",
      "            if max_oc=='all': max_oc=10000\n",
      "            for mo in range(min_oc,max_oc):\n",
      "                result = client.service.OccurrenceVolume(e1[1][i], e2[1][j],\n",
      "                                    'document',  datei, datef, 100, mo, 1 )\n",
      "                result2 = client.service.OccurrenceSentiment(e1[1][i], e2[1][j],\n",
      "                                    'block', 'sum',  datei, datef, 100, mo, 1 )\n",
      "    # use the urls to get full occurrence volume (all dates)\n",
      "    # store them in matrix \n",
      "    # last: 1= financial docs only, and 0= all\n",
      "    # 2: minimum occurrence threshold\n",
      "    # 'document'=whole, 'block'=paragraph\n",
      "    # financial sources= at least some fin. related entities appear. \n",
      "                result = sorted(result.TimelineVolume, key=lambda e: e.Date)\n",
      "                result2 = sorted(result2.TimelineIndex, key=lambda e: e.Date)\n",
      "                print  e2[0][j],mo,\",\",\n",
      "            #res+=[[e1[0][i],e2[0][j],result]]\n",
      "                b=[]; \n",
      "                b2=[];\n",
      "                for k in range(len(result)):\n",
      "                    b+=[[date2num(result[k][0]),int(result[k][1])]]\n",
      "                for k in range(len(result2)):\n",
      "                    b2+=[[date2num(result2[k][0]),int(result2[k][1])]]\n",
      "                print array(b)[:,1].sum()\n",
      "                if array(b)[:,1].sum()==0.: break\n",
      "            #b=array(b)\n",
      "            #b2=array(b2)\n",
      "                if log: \n",
      "                    print \"Occurrence:\", b\n",
      "                    print \"Sentiment:\", b2\n",
      "                if slick:\n",
      "                #print b\n",
      "                    b0+=Insert0([[b]], datei=datei, datef=datef)[0][0]\n",
      "                    #print b\n",
      "                    b02+=Insert0([[b2]], datei=datei, datef=datef)[0][0]\n",
      "                    #print b2\n",
      "                # Assuming slick: accumulate data\n",
      "                #print b2\n",
      "            \n",
      "            if out: \n",
      "                a+=[b]; \n",
      "                a2+=[b2]; \n",
      "        except AttributeError:\n",
      "            print \"!!(\", e1[0][i],\",\", e2[0][j],\", not found)\",\n",
      "            pass\n",
      "      if slick:\n",
      "                pth=CDSPath+\"files/Slick/\"\n",
      "                pth=[pth+\"Occurrence/\",pth+\"Sentiment/\"]\n",
      "                if not os.path.exists(pth[0]): os.makedirs(pth[0])\n",
      "                if not os.path.exists(pth[1]): os.makedirs(pth[1])\n",
      "      else:    pth=[RawOcPath,RawSentPath]\n",
      "      if savefile:\n",
      "                #print b\n",
      "                #print b2\n",
      "                if num2==['']:\n",
      "                    savetxt(pth[0]+\n",
      "                       'Oc-'+str(num1[i])+'('+datei+','+datef+'),min_oc=%d,max_oc=%s.csv' \\\n",
      "                       %(min_oc,str(max_oc)),\n",
      "                           b0, delimiter=',',fmt='%s')\n",
      "                    savetxt(pth[1]+\n",
      "                       'S-'+str(num1[i])+'('+datei+','+datef+'),min_oc=%d,max_oc=%s.csv' \\\n",
      "                       %(min_oc,str(max_oc)),\n",
      "                           b02, delimiter=',',fmt='%s')\n",
      "                else:\n",
      "                    savetxt(pth[0]+\n",
      "                           'Cooc-'+str(num1[i])+','+str(num2[j])+'('+datei+','+datef+'),min_oc=%d,max_oc=%s.csv' \\\n",
      "                       %(min_oc,str(max_oc)),\n",
      "                           b0, delimiter=',',fmt='%s')\n",
      "                    savetxt(pth[1]+\n",
      "                           'Co-S-'+str(num1[i])+','+str(num2[j])+'('+datei+','+datef+'),min_oc=%d,max_oc=%s.csv' \\\n",
      "                       %(min_oc,str(max_oc)),\n",
      "                           b02, delimiter=',',fmt='%s')\n",
      "    return array(a), array(a2)\n",
      "\n"
     ],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}