<div class="row res-int">
<div class="media"><img class="col-sm-4" src="img/pics/DNN.png">
<div class="media-body">
<h4 class="mt-2">Deep Learning</h4>
<hr class="hr-dark mr-3 wow fadeInLeft" data-wow-delay="0.3s">
<p>I am interested in understanding the nature of the weights in a deep neural network. In a recent paper we show it to be related to PCA&nbsp;</p>
</div>
</div>
</div>
<p>&nbsp;</p>
<p>Deep Neural Networks are quickly mastering many high-level tasks that we humans are good at. Yet, we still lack a good mathematical understanding of why they are able to achieve this feat.&nbsp;</p>
<p>I have am working on this problem. Together with Neda Rohani and Aggelos Katsaggelos, I have shown that in the lowest layers (closest to input) these networks are performing a type of supervised principal component analysis (PCA): performing PCA on inputs belonging to the same label class and using the PCs as weights.&nbsp;</p>
<p>In the next steps we want to derive how this process occurs recursively in higher layers and how it may lead to constructing a high-level representaion of the data. Understanding this may lead to much faster training algorithms.&nbsp;</p>